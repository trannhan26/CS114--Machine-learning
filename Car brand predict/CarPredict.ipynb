{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc và label dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_mapping = {\n",
    "    \"Others\": 0,\n",
    "    \"Honda\": 1,\n",
    "    \"Hyundai\": 2,\n",
    "    \"KIA\": 3,\n",
    "    \"Mazda\": 4,\n",
    "    \"Mitsubishi\" : 5,\n",
    "    \"Toyota\": 6,\n",
    "    \"Suzuki\": 7,\n",
    "    \"Vinfast\": 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brand_from_path(path, tag_mapping):\n",
    "    for brand in tag_mapping.keys():\n",
    "        if re.search(fr'\\b{brand}\\b', path, re.IGNORECASE):\n",
    "            return brand\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"clustering_results.csv\"\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BrandName'] = data['ImageFullPath'].apply(lambda x:extract_brand_from_path(x, tag_mapping))\n",
    "data['Label'] = data['BrandName'].map(tag_mapping).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageFullPath</th>\n",
       "      <th>ClusterID</th>\n",
       "      <th>BrandName</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...</td>\n",
       "      <td>1</td>\n",
       "      <td>Others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...</td>\n",
       "      <td>1</td>\n",
       "      <td>Others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...</td>\n",
       "      <td>4</td>\n",
       "      <td>Others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...</td>\n",
       "      <td>4</td>\n",
       "      <td>Others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...</td>\n",
       "      <td>1</td>\n",
       "      <td>Others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31793</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....</td>\n",
       "      <td>2</td>\n",
       "      <td>Vinfast</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31794</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....</td>\n",
       "      <td>4</td>\n",
       "      <td>Vinfast</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31795</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....</td>\n",
       "      <td>2</td>\n",
       "      <td>Vinfast</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31796</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....</td>\n",
       "      <td>4</td>\n",
       "      <td>Vinfast</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31797</th>\n",
       "      <td>/content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....</td>\n",
       "      <td>4</td>\n",
       "      <td>Vinfast</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ImageFullPath  ClusterID BrandName  \\\n",
       "0      /content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...          1    Others   \n",
       "1      /content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...          1    Others   \n",
       "2      /content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...          4    Others   \n",
       "3      /content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...          4    Others   \n",
       "4      /content/drive/My Drive/dataset/CS114_ML\\Others/21522373-21522499.L...          1    Others   \n",
       "...                                                  ...        ...       ...   \n",
       "31793  /content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....          2   Vinfast   \n",
       "31794  /content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....          4   Vinfast   \n",
       "31795  /content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....          2   Vinfast   \n",
       "31796  /content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....          4   Vinfast   \n",
       "31797  /content/drive/My Drive/dataset/CS114_ML\\Vinfast/22521692-22521676....          4   Vinfast   \n",
       "\n",
       "       Label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "31793      8  \n",
       "31794      8  \n",
       "31795      8  \n",
       "31796      8  \n",
       "31797      8  \n",
       "\n",
       "[31798 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>ImageCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Others</td>\n",
       "      <td>4469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Honda</td>\n",
       "      <td>2769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai</td>\n",
       "      <td>3088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KIA</td>\n",
       "      <td>2529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mazda</td>\n",
       "      <td>2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>5092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Suzuki</td>\n",
       "      <td>5965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vinfast</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand  ImageCount\n",
       "0      Others        4469\n",
       "1       Honda        2769\n",
       "2     Hyundai        3088\n",
       "3         KIA        2529\n",
       "4       Mazda        2989\n",
       "5  Mitsubishi        2689\n",
       "6      Toyota        5092\n",
       "7      Suzuki        5965\n",
       "8     Vinfast        2208"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_counts = data['BrandName'].value_counts()\n",
    "\n",
    "brand_counts_df = brand_counts.reset_index()\n",
    "brand_counts_df.columns = ['Brand', 'ImageCount']\n",
    "\n",
    "ordered_brands = list(tag_mapping.keys())\n",
    "ordered_brand_counts = brand_counts.reindex(ordered_brands).fillna(0).astype(int)\n",
    "\n",
    "ordered_brand_counts_df = ordered_brand_counts.reset_index()\n",
    "ordered_brand_counts_df.columns = ['Brand', 'ImageCount']\n",
    "ordered_brand_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_img(file_paths, img_size):\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            img = load_img(path, target_size=img_size)\n",
    "            img = img_to_array(img) / 255.0\n",
    "            images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f'Error loading image {path}: {e}')\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, img_size=(224, 224)):\n",
    "    data = data[data['ImageFullPath'].apply(os.path.exists)]\n",
    "    file_paths = data['ImageFullPath'].values\n",
    "    labels = to_categorical(data['Label'], num_classes=len(tag_mapping))\n",
    "\n",
    "    # chia tập train và tập test\n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "        file_paths, labels, test_size=0.2, random_state=42, stratify=data['Label']\n",
    "    )\n",
    "\n",
    "    X_train = processing_img(train_paths, img_size)\n",
    "    X_test = processing_img(test_paths, img_size)\n",
    "\n",
    "    return X_train, X_test, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weight class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(tag_mapping)),\n",
    "    y=data['Label'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      "Class 0: Weight 0.812\n",
      "Class 1: Weight 1.311\n",
      "Class 2: Weight 1.154\n",
      "Class 3: Weight 1.402\n",
      "Class 4: Weight 1.182\n",
      "Class 5: Weight 1.313\n",
      "Class 6: Weight 0.693\n",
      "Class 7: Weight 0.592\n",
      "Class 8: Weight 1.614\n"
     ]
    }
   ],
   "source": [
    "print(\"Class weights:\")\n",
    "for class_index, weight in class_weights.items():\n",
    "    print(f\"Class {class_index}: Weight {weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {i: weight for i, weight in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:100]:  \n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(tag_mapping), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_car_brand_model_classweight.keras', monitor='val_accuracy', save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 786ms/step - accuracy: 0.1391 - loss: 2.9155 - val_accuracy: 0.2299 - val_loss: 2.2843\n",
      "Epoch 2/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 704ms/step - accuracy: 0.2152 - loss: 2.4708 - val_accuracy: 0.3052 - val_loss: 2.0430\n",
      "Epoch 3/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 693ms/step - accuracy: 0.2725 - loss: 2.2227 - val_accuracy: 0.3385 - val_loss: 1.9297\n",
      "Epoch 4/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 746ms/step - accuracy: 0.3143 - loss: 2.0538 - val_accuracy: 0.3678 - val_loss: 1.8424\n",
      "Epoch 5/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 574ms/step - accuracy: 0.3613 - loss: 1.9007 - val_accuracy: 0.4057 - val_loss: 1.7637\n",
      "Epoch 6/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 578ms/step - accuracy: 0.3863 - loss: 1.8010 - val_accuracy: 0.4280 - val_loss: 1.6950\n",
      "Epoch 7/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 575ms/step - accuracy: 0.4268 - loss: 1.6760 - val_accuracy: 0.4410 - val_loss: 1.6533\n",
      "Epoch 8/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 578ms/step - accuracy: 0.4505 - loss: 1.6041 - val_accuracy: 0.4522 - val_loss: 1.6108\n",
      "Epoch 9/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 571ms/step - accuracy: 0.4798 - loss: 1.4837 - val_accuracy: 0.4730 - val_loss: 1.5623\n",
      "Epoch 10/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 566ms/step - accuracy: 0.5065 - loss: 1.4075 - val_accuracy: 0.4851 - val_loss: 1.5166\n",
      "Epoch 11/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 568ms/step - accuracy: 0.5364 - loss: 1.3369 - val_accuracy: 0.4961 - val_loss: 1.4760\n",
      "Epoch 12/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 568ms/step - accuracy: 0.5519 - loss: 1.2695 - val_accuracy: 0.5157 - val_loss: 1.4453\n",
      "Epoch 13/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 652ms/step - accuracy: 0.5762 - loss: 1.2037 - val_accuracy: 0.5245 - val_loss: 1.4035\n",
      "Epoch 14/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 571ms/step - accuracy: 0.6005 - loss: 1.1128 - val_accuracy: 0.5333 - val_loss: 1.3794\n",
      "Epoch 15/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 586ms/step - accuracy: 0.6194 - loss: 1.0762 - val_accuracy: 0.5443 - val_loss: 1.3548\n",
      "Epoch 16/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 595ms/step - accuracy: 0.6403 - loss: 1.0044 - val_accuracy: 0.5498 - val_loss: 1.3468\n",
      "Epoch 17/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 568ms/step - accuracy: 0.6633 - loss: 0.9416 - val_accuracy: 0.5566 - val_loss: 1.3316\n",
      "Epoch 18/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 570ms/step - accuracy: 0.6821 - loss: 0.8833 - val_accuracy: 0.5665 - val_loss: 1.3103\n",
      "Epoch 19/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 684ms/step - accuracy: 0.7010 - loss: 0.8510 - val_accuracy: 0.5802 - val_loss: 1.2777\n",
      "Epoch 20/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 628ms/step - accuracy: 0.7136 - loss: 0.8031 - val_accuracy: 0.5836 - val_loss: 1.2643\n",
      "Epoch 21/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 582ms/step - accuracy: 0.7359 - loss: 0.7510 - val_accuracy: 0.5871 - val_loss: 1.2579\n",
      "Epoch 22/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 570ms/step - accuracy: 0.7454 - loss: 0.7076 - val_accuracy: 0.5915 - val_loss: 1.2623\n",
      "Epoch 23/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 657ms/step - accuracy: 0.7688 - loss: 0.6473 - val_accuracy: 0.5965 - val_loss: 1.2679\n",
      "Epoch 24/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 713ms/step - accuracy: 0.7826 - loss: 0.6134 - val_accuracy: 0.6044 - val_loss: 1.2491\n",
      "Epoch 25/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 708ms/step - accuracy: 0.7909 - loss: 0.5869 - val_accuracy: 0.6096 - val_loss: 1.2283\n",
      "Epoch 26/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 625ms/step - accuracy: 0.8041 - loss: 0.5454 - val_accuracy: 0.6124 - val_loss: 1.2278\n",
      "Epoch 27/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 667ms/step - accuracy: 0.8160 - loss: 0.5197 - val_accuracy: 0.6176 - val_loss: 1.2245\n",
      "Epoch 28/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 677ms/step - accuracy: 0.8276 - loss: 0.4841 - val_accuracy: 0.6236 - val_loss: 1.2188\n",
      "Epoch 29/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 682ms/step - accuracy: 0.8452 - loss: 0.4407 - val_accuracy: 0.6245 - val_loss: 1.2144\n",
      "Epoch 30/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 667ms/step - accuracy: 0.8567 - loss: 0.4066 - val_accuracy: 0.6291 - val_loss: 1.2206\n",
      "Epoch 31/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 683ms/step - accuracy: 0.8616 - loss: 0.3885 - val_accuracy: 0.6299 - val_loss: 1.2144\n",
      "Epoch 32/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 676ms/step - accuracy: 0.8744 - loss: 0.3538 - val_accuracy: 0.6294 - val_loss: 1.2357\n",
      "Epoch 33/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 662ms/step - accuracy: 0.8821 - loss: 0.3358 - val_accuracy: 0.6308 - val_loss: 1.2387\n",
      "Epoch 34/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 673ms/step - accuracy: 0.8942 - loss: 0.3074 - val_accuracy: 0.6303 - val_loss: 1.2552\n",
      "Epoch 35/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 675ms/step - accuracy: 0.8972 - loss: 0.2978 - val_accuracy: 0.6316 - val_loss: 1.2561\n",
      "Epoch 36/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 683ms/step - accuracy: 0.9097 - loss: 0.2632 - val_accuracy: 0.6321 - val_loss: 1.2736\n",
      "Epoch 37/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 660ms/step - accuracy: 0.9173 - loss: 0.2487 - val_accuracy: 0.6398 - val_loss: 1.2471\n",
      "Epoch 38/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 582ms/step - accuracy: 0.9219 - loss: 0.2272 - val_accuracy: 0.6395 - val_loss: 1.2599\n",
      "Epoch 39/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 594ms/step - accuracy: 0.9268 - loss: 0.2119 - val_accuracy: 0.6409 - val_loss: 1.2770\n",
      "Epoch 40/40\n",
      "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 579ms/step - accuracy: 0.9403 - loss: 0.1929 - val_accuracy: 0.6436 - val_loss: 1.2740\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 312ms/step - accuracy: 0.74 - loss: 1.2376\n",
      "Test accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 315ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Others       0.65      0.62      0.63       894\n",
      "       Honda       0.67      0.60      0.63       554\n",
      "     Hyundai       0.65      0.63      0.64       618\n",
      "         KIA       0.60      0.59      0.59       506\n",
      "       Mazda       0.75      0.78      0.76       598\n",
      "  Mitsubishi       0.55      0.62      0.58       538\n",
      "      Toyota       0.70      0.69      0.69      1018\n",
      "      Suzuki       0.82      0.80      0.81      1193\n",
      "     Vinfast       0.76      0.80      0.78       441\n",
      "\n",
      "    accuracy                           0.74      6360\n",
      "   macro avg       0.69      0.70      0.69      6360\n",
      "weighted avg       0.76      0.80      0.73      6360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "y_test_labels = y_test.argmax(axis=1)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred, target_names=list(tag_mapping.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_car_brand_model_classweight.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
